{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ffb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694d6e8",
   "metadata": {},
   "source": [
    "#### Step 1: Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ce7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed train data\n",
    "df_train_preprocessed= pd.read_csv('/Users/smirghor/Library/Mobile Documents/com~apple~CloudDocs/Personal/Machine Learning Projects/data.nosync/amazon_review_polarity_csv/preprocessed_reviews_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40a5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed test data\n",
    "df_test_preprocessed = pd.read_csv('/Users/smirghor/Library/Mobile Documents/com~apple~CloudDocs/Personal/Machine Learning Projects/data.nosync/amazon_review_polarity_csv/preprocessed_reviews_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d59e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>['im', 'reading', 'lot', 'review', 'saying', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>['soundtrack', 'favorite', 'music', 'time', 'h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>['truly', 'like', 'soundtrack', 'enjoy', 'vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>['youve', 'played', 'game', 'know', 'divine', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>an absolute masterpiece</td>\n",
       "      <td>['quite', 'sure', 'actually', 'taking', 'time'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              title   \n",
       "0         2              The best soundtrack ever to anything.  \\\n",
       "1         2                                           Amazing!   \n",
       "2         2                               Excellent Soundtrack   \n",
       "3         2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "4         2                            an absolute masterpiece   \n",
       "\n",
       "                                                text  \n",
       "0  ['im', 'reading', 'lot', 'review', 'saying', '...  \n",
       "1  ['soundtrack', 'favorite', 'music', 'time', 'h...  \n",
       "2  ['truly', 'like', 'soundtrack', 'enjoy', 'vide...  \n",
       "3  ['youve', 'played', 'game', 'know', 'divine', ...  \n",
       "4  ['quite', 'sure', 'actually', 'taking', 'time'...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0568f966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>['despite', 'fact', 'played', 'small', 'portio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Batteries died within a year ...</td>\n",
       "      <td>['bought', 'charger', 'jul', '2003', 'worked',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>works fine, but Maha Energy is better</td>\n",
       "      <td>['check', 'maha', 'energy', 'website', 'powere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the non-audiophile</td>\n",
       "      <td>['reviewed', 'quite', 'bit', 'combo', 'player'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>DVD Player crapped out after one year</td>\n",
       "      <td>['also', 'began', 'incorrect', 'disc', 'proble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              title   \n",
       "0         2  One of the best game music soundtracks - for a...  \\\n",
       "1         1                   Batteries died within a year ...   \n",
       "2         2              works fine, but Maha Energy is better   \n",
       "3         2                       Great for the non-audiophile   \n",
       "4         1              DVD Player crapped out after one year   \n",
       "\n",
       "                                                text  \n",
       "0  ['despite', 'fact', 'played', 'small', 'portio...  \n",
       "1  ['bought', 'charger', 'jul', '2003', 'worked',...  \n",
       "2  ['check', 'maha', 'energy', 'website', 'powere...  \n",
       "3  ['reviewed', 'quite', 'bit', 'combo', 'player'...  \n",
       "4  ['also', 'began', 'incorrect', 'disc', 'proble...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f0b12",
   "metadata": {},
   "source": [
    "#### Step 2: Convert text to numerical features. \n",
    "Options are: Bag of word (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), and Word Embeddings (Optional for Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3060bce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#convert strings in train and test set to list on column 'text'\n",
    "\n",
    "df_train_preprocessed['text'] = df_train_preprocessed['text'].apply(lambda x: eval(x))\n",
    "df_test_preprocessed['text'] = df_test_preprocessed['text'].apply(lambda x: eval(x))\n",
    "\n",
    "#check the type of column 'text'\n",
    "print(type(df_train_preprocessed['text'].iloc[0]))\n",
    "print(type(df_test_preprocessed['text'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea77dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    im reading lot review saying best game soundtr...\n",
      "1    soundtrack favorite music time hand intense sa...\n",
      "2    truly like soundtrack enjoy video game music p...\n",
      "3    youve played game know divine music every sing...\n",
      "4    quite sure actually taking time read played ga...\n",
      "Name: text, dtype: object\n",
      "0    despite fact played small portion game music h...\n",
      "1    bought charger jul 2003 worked ok design nice ...\n",
      "2    check maha energy website powerex mhc204f char...\n",
      "3    reviewed quite bit combo player hesitant due u...\n",
      "4    also began incorrect disc problem ive read vcr...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#join the tokenized words into a single string for each row\n",
    "df_train_preprocessed['text'] = df_train_preprocessed['text'].apply(lambda x: ' '.join(x))\n",
    "df_test_preprocessed['text'] = df_test_preprocessed['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "#verify the joined text\n",
    "print(df_train_preprocessed['text'].head())\n",
    "print(df_test_preprocessed['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08064634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with the simplest model, Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#Fit and transform the train data\n",
    "X_train = vectorizer.fit_transform(df_train_preprocessed['text'])\n",
    "\n",
    "#Transform the test data using the same vocabulary\n",
    "X_test =vectorizer.transform(df_test_preprocessed['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b29018",
   "metadata": {},
   "source": [
    "Step 3: Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64d63ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8745421863554659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.87      0.87    200000\n",
      "           2       0.87      0.88      0.88    199999\n",
      "\n",
      "    accuracy                           0.87    399999\n",
      "   macro avg       0.87      0.87      0.87    399999\n",
      "weighted avg       0.87      0.87      0.87    399999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, df_train_preprocessed['polarity'])\n",
    "\n",
    "#make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(df_test_preprocessed['polarity'], y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#Print a classification report for detailed evaluation\n",
    "print(classification_report(df_test_preprocessed['polarity'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ae12e",
   "metadata": {},
   "source": [
    "#### Time for a more advanced model to train this dataset like Deep Learning Models for NLP: RNNs, LSTMs, and GRUs\n",
    "- Vanilla RNN: Use for tasks with short sequences or when computational efficiency is critical.\n",
    "- LSTM: Use for tasks with longer sequences, where retaining long-term dependencies is crucial (e.g., machine translation, long text classification).\n",
    "- GRU: Use when you want a compromise between LSTM’s performance and RNN’s efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa7186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data again: \n",
    "#the preprocessed train data\n",
    "df_train_preprocessed= pd.read_csv('/Users/smirghor/Library/Mobile Documents/com~apple~CloudDocs/Personal/Machine Learning Projects/data.nosync/amazon_review_polarity_csv/preprocessed_reviews_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fc8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed test data\n",
    "df_test_preprocessed = pd.read_csv('/Users/smirghor/Library/Mobile Documents/com~apple~CloudDocs/Personal/Machine Learning Projects/data.nosync/amazon_review_polarity_csv/preprocessed_reviews_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7056b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense \n",
    "\n",
    "#LSTM model \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128)) # Embedding layer for word vector\n",
    "model.add(LSTM(units=128, return_sequences=False)) #LSTM layer\n",
    "model.add(Dense(units=1, activation='sigmoid')) #output layer for binary classification\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d721790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data\n",
    "#step 1: fit a tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#initialize the tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000) #choose vocab size based on dataset size\n",
    "tokenizer.fit_on_texts(df_train_preprocessed['text']) #fit on the training data\n",
    "\n",
    "#Convert text to sequences\n",
    "X_train = tokenizer.texts_to_sequences(df_train_preprocessed['text'])\n",
    "X_test = tokenizer.texts_to_sequences(df_test_preprocessed['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6210387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: pad the sequence\n",
    "#LSTM model expects sequences to be of the same length, so padding is neccesary\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#pad sequences to ensure they are the same length\n",
    "X_train = pad_sequences(X_train, maxlen=100)\n",
    "X_test = pad_sequences(X_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7379b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine y_train and y_test\n",
    "y_train = df_train_preprocessed['polarity']\n",
    "y_test = df_test_preprocessed['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77912706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m   658/112500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13:34\u001b[0m 72ms/step - accuracy: 0.4888 - loss: -15.5928"
     ]
    }
   ],
   "source": [
    "#step 3: traint he LSTM model\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
